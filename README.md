Code for paper: [Shapley Values for Explaining Reinforcement Learning](https://arxiv.org/abs/2306.05810) 

An XRL feature-influence method.

If you use this respository, please cite the following:

@misc{beechey2023explaining,
      title={Explaining Reinforcement Learning with Shapley Values}, 
      author={Daniel Beechey and Thomas M. S. Smith and \"{O}zgür Şimşek},
      year={2023},
      eprint={2306.05810},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
